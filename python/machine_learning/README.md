## 吴恩达的目录：

- 单变量线性回归
    - 模型表示
    - 代价函数
    - 梯度下降
- 多变量线性回归
    - 多变量梯度下降 --> 特征缩放 学习率
    - 特征和多项式回归
    - 正规方程(及不可逆性)
- Octave 教程
    - 基本操作 移动数据 计算数据 绘图数据 控制语句 向量化
- 逻辑回归
    - 分类问题
    - 假说问题
    - 判定边界
    - 代价函数
    - 简化成本函数和梯度下降
    - 高级优化
    - 多类别分类: 一对多
- 正则化
    - 过拟合的问题
    - 代价函数
    - 正则化线性回归
    - 正则化的逻辑回归模型
- 神经网络
    - 非线性假设
    - 神经元和大脑
    - 模型表示1/2
    - 多类分类
- 神经网络的学习
    - 代价函数
    - 反向传播算法
    - 梯度检验
    - 随机初始化
    - 自主驾驶
- 十之后的暂定

## PS.

- 24.11.19  
  ps: 开始看机器学习的东西了 这部分都是python相关的 所以就在这里更新吧  
  已经忘了前段时间学习的python了 已经忘光了 那会儿看md 记不起来都 之后等mac回来之后在学吧
- 24.11.20  
  ps: 今天还是背单词 看了一下那个线性回归的代价函数(cost function) 还有梯度下降算法  
  这些都是和导数还有线代有关的 我现在也看不懂 不知道为什么就突然出来这么个公式 然后就推导出新的公式  
  理解上还是有一定难度的 单单看某个公式 知道它的目的 但是合到一起就不会了  
  确实这个算法需要很高的学历或者造诣 毕竟这些个公式 算法 都不是一般人可以学会的  
  这周把这个梯度下降搞会了 或者代码会写了 这周就还算有收获
- 24.11.21  
  ps: 今天刷抖音看到一个视频说是看这种英文视频中文字幕的 一来学视频内容 二来学英语 这样是哪个都学不好的  
  因为你没有去用英语理解英语 所以还是找一个中文的视频来学这个机器学习的东西  
  我发现自己的思维总是固化 非得按照吴恩达那个结构去学 但是 后来想了一想 只要入了门 只要了解了 会写了 其实就可以了  
  不存在什么非得按照这个结构来学的 明天继续
- 24.11.22
  ps: 今天看了几条视频 一心想着明天周六赛季更新冲战神的事儿了 所以今天没怎么看视频 但是单词还是背了的 一会在复习一下  
  明天一定一定要上战神 了却一个很久的心愿吧 奥里给 加油!!!